<!DOCTYPE html>
<html lang="en">
  <!-- Beautiful Jekyll | MIT license | Copyright Dean Attali 2016 -->
  <head>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Understanding Neural Networks with Layerwise Relevance Propagation and Deep Taylor Series</title>

  <meta name="author" content="Dan Shiebler" />
  
  

  <link rel="alternate" type="application/rss+xml" title="Dan Shiebler - Thoughts on Math and ML" href="/feed.xml" />

  
    
      <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" />
    
      
  
  
    
      <link rel="stylesheet" href="/css/bootstrap.min.css" />
    
      <link rel="stylesheet" href="/css/bootstrap-social.css" />
    
      <link rel="stylesheet" href="/css/main.css" />
    
    
  
  
    
      <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
    
      <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
    
  

    
  
  

  

  <!-- Facebook OpenGraph tags -->
  <meta property="og:title" content="Understanding Neural Networks with Layerwise Relevance Propagation and Deep Taylor Series" />
  <meta property="og:type" content="website" />
  
  <meta property="og:url" content="http://localhost:4000/2017-04-16-deep-taylor-lrp/" />
  
  
  <meta property="og:image" content="http://localhost:4000/img/DanGood.jpg" />
  
  
  <!-- Twitter summary cards -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@" />
  <meta name="twitter:creator" content="@" />
  <meta name="twitter:title" content="Understanding Neural Networks with Layerwise Relevance Propagation and Deep Taylor Series" />
  <meta name="twitter:description" content="Deep neural networks are some of the most powerful learning algorithms that have ever been developed. Unfortunately, they are also some of the most complex. The hierarchical non-linear transformations that neural networks apply to data can be nearly impossible to understand. This problem is exacerbated by the non-determinism of neural..." />
  
  <meta name="twitter:image" content="http://localhost:4000/img/DanGood.jpg" />
  
  
<script data-ad-client="ca-pub-5902123796191074" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>


  <body>
  
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://localhost:4000">Dan Shiebler</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
          <li>
            
            





<a href="/Publications">Publications</a>

          </li>
        
        
        
          <li>
            
            





<a href="/Talks">Talks</a>

          </li>
        
        
        
          <li>
            
            





<a href="/Other Posts">Other Posts</a>

          </li>
        
        
        
          <li>
            
            





<a href="/Hosted Meetups">Hosted Meetups</a>

          </li>
        
        
        
          <li>
            
            





<a href="/aboutme">About Me</a>

          </li>
        
        
      </ul>
    </div>

	
	<div class="avatar-container">
	  <div class="avatar-img-border">
	    <a href="http://localhost:4000 ">
	      <img class="avatar-img" src="/img/DanGood.jpg" />
		</a>
	  </div>
	</div>
	

  </div>
</nav>


    <!-- TODO this file has become a mess, refactor it -->





<header class="header-section ">

<div class="intro-header no-img">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-heading">
          <h1>Understanding Neural Networks with Layerwise Relevance Propagation and Deep Taylor Series</h1>
		  
		  
		  
		  <span class="post-meta">Posted on April 16, 2017</span>
		  
        </div>
      </div>
    </div>
  </div>
</div>
</header>




<div class="container">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

      <article role="main" class="blog-post">
        <script> 
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82391879-1', 'auto');
  ga('send', 'pageview');

</script>

<p>Deep neural networks are some of the most powerful learning algorithms that have ever been developed. Unfortunately, they are also some of the most complex. The hierarchical non-linear transformations that neural networks apply to data can be nearly impossible to understand. This problem is exacerbated by the non-determinism of neural network training regimes. Very often small changes in the hyperparameters of a network can dramatically affect the network’s ability to learn.</p>

<p>In order to combat this problem, deep learning researchers use a wide array of tools and techniques for monitoring a neural network’s learning process. Even just visualizing a histogram of each layer’s weight matrix or gradient can help researchers spot problems.</p>

<p><img src="/img/tensorboard.png" alt="Picture of tensorboard" /></p>

<p>After training a network, it’s often helpful for researchers to try to understand how it forms predictions. For example, in <a href="https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf">this paper</a> researchers use a technique for visualizing how each layer in a convolutional neural network processes an input image by essentially reversing the hierarchical image encoding process.</p>

<p>One question that researchers often ask when evaluating a machine learning model’s prediction on some input is “what features were most important in forming this prediction?” One way to answer this question is to see how the model’s prediction changes when we occlude different parts of the image. Lets say we have a model that is trained to recognize a large number of image classes, including “cat,” and we feed it this image:</p>

<p><img src="/img/cat_litter_box.png" alt="Cat sitting next to litter box" /></p>

<p>If the model is well trained, then it will predict “cat.” But why is it making that prediction? Has it learned to recognize the shape of the cat, or is it just using the litter box next to it as a context clue? We can test this by feeding the model the following images:</p>

<p><img src="/img/cat_no_litter_box.png" alt="occluded cat next to litter box" /><br />
<img src="/img/no_cat_litter_box.png" alt="Cat sitting next to occluded litter box" /></p>

<p>If the model generates the correct prediction for the first image and the incorrect prediction for the second image, then we can assume that the model was relying more heavily on the cat’s shape than the context cues in forming its original prediction. But if the model generates the correct prediction in both cases, then we still don’t know the relative weights that the model is placing on the context cues in forming its prediction.</p>

<h2 id="layerwise-relevance-propagation">Layerwise Relevance Propagation</h2>

<p>Layerwise Relevance Propagation (LRP) is a technique for determining which features in a particular input vector contribute most strongly to a neural network’s output. The technique was originally described in <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140">this paper</a>.</p>

<p>The goal of LRP is to define some relevance measure R over the input vector such that we can express the network output as the sum of the values of R:</p>

<p><img src="/img/relevance_sum.png" alt="relevance sum equation" /></p>

<p>Where \(f\) is the neural network forward pass function. For example, in the case where the input to the network is a natural image, we are decomposing the output of the network into the sum of the relevances of the pixels in the input image. In order to perform this decomposition, we begin with the “relevance” being concentrated at the output node in the graph, and then iteratively “propagate” it backwards through the network.</p>

<p><img src="/img/LRP_overview.png" alt="LRP overview" /></p>

<p>At each layer, the total relevance value is preserved, and the final propagation maps the relevance back onto the input vector. This process is similar in spirit to backpropagation.</p>

<p><img src="/img/relevance_propagation.png" alt="picture with relevance pointing at the final layer, then moving back to the first layer" /></p>

<p>When we perform the propagation procedure, we need to determine how to map the relevance back from some neuron \(n\) at layer \(k\) to the set of neurons \(n_i\) at layer \(k-1\) who feed into neuron \(n\). That is, we need to define a vector valued function that takes in the relevance \(R\) at neuron \(n\), the activation \(x\) of neuron \(n\), the activations \(x_i\) of the neurons \(n_i\) at layer \(k-1\), and the weight matrix \(w\) that connects the neurons \(n_i\) to \(n\), and outputs the relevance of each neuron \(n_i\). Ideally this function will assign higher weights to neurons that had a larger role in influencing the value of \(n\). The original LRP paper defines a set of constraints from which we can derive a number of different relevance propagation functions, but in this post I’m going to focus on the deep taylor decomposition.</p>

<h2 id="deep-taylor-decomposition">Deep Taylor Decomposition</h2>

<p>Let’s consider the scalar valued forward propagation function that maps from the layer \(k-1\) activations \(x_i\) to node \(n\)’s activation \(x\). The \(i^{th}\) partial derivative of this function measures the strength of the relationship between \(n_i\)’s activation \(x_i\) and \(n\)’s activation \(x\). So if we can decompose this function in terms of its partial derivatives, we can use that decomposition to approximate the relevance propagation function. Luckily, we can do exactly this with a Taylor Series.</p>

<p>Remember that we can use a Taylor series to approximate the value of a function \(f\) near a point \(x_0\) with:</p>

<p><img src="/img/taylor_decomposition.png" alt="Equation for taylor series" /></p>

<p>The closer that \(x\) is to \(x_0\), the better the approximation. One clever thing that we can do is set \(x_0\) to be a “root point” of the forward propagation function, that is, a point such that \(f(x_0) = 0\). This simplifies the above Taylor expression to:</p>

<p><img src="/img/taylor_decomposition_at_root.png" alt="Equation for taylor series with root point" /></p>

<p>Root points of the forward propagation function are located at the local decision boundary, so the gradients along that boundary point give us the most information about how the function separates the input by class.</p>

<p><img src="/img/taylor_decomposition_outline.png" alt="taylor decomposition outline" /></p>

<h2 id="lrp-results">LRP Results</h2>

<p>LRP can produce some really helpful and nice-looking visualizations of how a neural network interprets an image.</p>

<p>Here’s how the VGG network interprets a few images:</p>

<p><img src="/img/Shark_LRP.png" alt="Shark_LRP" />
<img src="/img/Dog_LRP.png" alt="Dog_LRP" />
<img src="/img/Glasses_LRP.png" alt="Glasses_LRP" />
<img src="/img/TIE_LRP.png" alt="ETIE_LRP" /></p>

<p>I implemented a simple TensorFlow-based LRP <a href="https://github.com/dshieble/Tensorflow_Deep_Taylor_LRP">here</a>. If you’re interested in using it in your research, feel free to send me an email at danshiebler@gmail.com.</p>

<h2 id="conclusion-and-further-reading">Conclusion and Further Reading</h2>

<p>Layerwise Relevance Propagation is just one of many techniques to help us better understand machine learning algorithms. As machine learning algorithms become more complex and more powerful, we will need more techniques like LRP in order to continue to understand and improve them.</p>

<p>If you’d like to learn more about LRP and Deep Taylor Decompositions, I would highly recommend checking out <a href="http://www.heatmapping.org/deeptaylor/">this website</a> as well as the <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140#sec002">original LRP paper</a> and this <a href="https://arxiv.org/pdf/1512.02479.pdf">Deep Taylor Decomposition Paper</a>.</p>

      </article>

      
        <div class="blog-tags">
          Tags:
          
            Tensorflow, Layerwise, Relevance, Propagation, Deep, Taylor, Series, Visualization
          
        </div>
      

      
        <!-- Check if any share-links are active -->




<section id = "social-share-section">

  <!--- Share on Twitter -->
  

  <!--- Share on Facebook -->
  
    <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2017-04-16-deep-taylor-lrp/"
      class="btn btn-social-icon btn-facebook" title="Share on Facebook">
      <span class="fa fa-fw fa-facebook" aria-hidden="true"></span>
    </a>
  

  <!--- Share on Google Plus -->
  

  <!--- Share on LinkedIn -->
  
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/2017-04-16-deep-taylor-lrp/"
      class="btn btn-social-icon btn-linkedin" title="Share on LinkedIn">
      <span class="fa fa-fw fa-linkedin" aria-hidden="true"></span>
    </a>
  

</section>


      

      <ul class="pager blog-pager">
        
        <li class="previous">
          <a href="/2017-02-12-monty-hall/" data-toggle="tooltip" data-placement="top" title="Exploring Assumptions with Monty Hall and Blue Eyed Islanders">&larr; Previous Post</a>
        </li>
        
        
        <li class="next">
          <a href="/2017-06-25-metrics/" data-toggle="tooltip" data-placement="top" title="R and R^2, the relationship between correlation and the coefficient of determination.">Next Post &rarr;</a>
        </li>
        
      </ul>

      
        <div class="disqus-comments">
          

        </div>
      
    </div>
  </div>
</div>

    <footer>
  <div class="container beautiful-jekyll-footer">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          <li>
            <a href="https://github.com/dshieble" title="GitHub">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
		  
          <li>
            <a href="mailto:danshiebler@gmail.com" title="Email me">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
          <li>
            <a href="https://linkedin.com/in/dan-shiebler-10219b42#Dan Shiebler" title="LinkedIn">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
		  
      
      
		  
        </ul>
        <p class="copyright text-muted">
		  Dan Shiebler
		  &nbsp;&bull;&nbsp;
		  2021

		  
	    </p>
	        <!-- Please don't remove this, keep my open source work credited :) -->
		<p class="theme-by text-muted">
		  Theme by
		  <a href="http://deanattali.com/beautiful-jekyll/">beautiful-jekyll</a>
		</p>
      </div>
    </div>
  </div>
</footer>

  
    






  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script>
      	if (typeof jQuery == 'undefined') {
      	  document.write('<script src="/js/jquery-1.11.2.min.js"></scr' + 'ipt>');
      	}
      </script>
    
  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
	<script src="/js/bootstrap.min.js"></script>
    
  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
	<script src="/js/main.js"></script>
    
  




  
  <script>
    !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);
    },s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='//static.ads-twitter.com/uwt.js',
    a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');
    // Insert Twitter Pixel ID and Standard Event data below
    twq('init','o5592');
    twq('track','PageView');
  </script>
  </body>
</html>
