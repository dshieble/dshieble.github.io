<!DOCTYPE html>
<html lang="en">
  <!-- Beautiful Jekyll | MIT license | Copyright Dean Attali 2016 -->
  <head>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Musical TensorFlow, Part 2 - How to build an RNN-RBM in TensorFlow for making longer musical compositions</title>

  <meta name="author" content="Dan Shiebler" />
  
  

  <link rel="alternate" type="application/rss+xml" title="Dan Shiebler - A place for me to share some of the things that I spend my time on." href="/feed.xml" />

  
    
      <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" />
    
      
  
  
    
      <link rel="stylesheet" href="/css/bootstrap.min.css" />
    
      <link rel="stylesheet" href="/css/bootstrap-social.css" />
    
      <link rel="stylesheet" href="/css/main.css" />
    
    
  
  
    
      <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
    
      <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
    
  

    
  
  

  

  <!-- Facebook OpenGraph tags -->
  <meta property="og:title" content="Musical TensorFlow, Part 2 - How to build an RNN-RBM in TensorFlow for making longer musical compositions" />
  <meta property="og:type" content="website" />
  
  <meta property="og:url" content="http://dshieble.github.io/2015-08-17-musical-tensorflow-part-two-the-rnn-rbm/" />
  
  
  <meta property="og:image" content="http://dshieble.github.io/img/dan2.png" />
  
  
  <!-- Twitter summary cards -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@" />
  <meta name="twitter:creator" content="@" />
  <meta name="twitter:title" content="Musical TensorFlow, Part 2 - How to build an RNN-RBM in TensorFlow for making longer musical compositions" />
  <meta name="twitter:description" content="Welcome to part 2 of the Musical TensorFlow series! In the last post, we built an RBM in TensorFlow for making short pieces of music. Today, we’re going to learn how to compose longer and more complex musical pieces with a more involved model: the RNN-RBM. To warm you up,..." />
  
  <meta name="twitter:image" content="http://dshieble.github.io/img/dan2.png" />
  
  
</head>


  <body>
  
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://dshieble.github.io">Dan Shiebler</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
          <li>
            
            





<a href="/aboutme">About Me</a>

          </li>
        
        
      </ul>
    </div>

	
	<div class="avatar-container">
	  <div class="avatar-img-border">
	    <a href="http://dshieble.github.io ">
	      <img class="avatar-img" src="/img/dan2.png" />
		</a>
	  </div>
	</div>
	

  </div>
</nav>


    <!-- TODO this file has become a mess, refactor it -->





<header class="header-section ">

<div class="intro-header no-img">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-heading">
          <h1>Musical TensorFlow, Part 2 - How to build an RNN-RBM in TensorFlow for making longer musical compositions</h1>
		  
		  
		  
		  <span class="post-meta">Posted on August 17, 2015</span>
		  
        </div>
      </div>
    </div>
  </div>
</div>
</header>




<div class="container">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

      <article role="main" class="blog-post">
        <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82391879-1', 'auto');
  ga('send', 'pageview');

</script>

<p>Welcome to part 2 of the Musical TensorFlow series! In <a href="http://danshiebler.com/2015-08-10-musical-tensorflow-rbm/">the last post</a>, we built an RBM in TensorFlow for making short pieces of music. Today, we’re going to learn how to compose longer and more complex musical pieces with a more involved model: the RNN-RBM.</p>

<p>To warm you up, here’s are some examples of music that this network created:</p>

<audio src="/audio/9.mp3" controls="" preload=""></audio>
<audio src="/audio/4.mp3" controls="" preload=""></audio>

<h2 id="concepts">Concepts</h2>

<h3 id="the-rnn">The RNN</h3>

<p>A <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Network</a> is a neural network architecture that can handle sequences of vectors. This makes it perfect for working with temporal data. For example, RNNs are excellent at tasks such as predicting the next word in a sentence or forecasting a time series.</p>

<p>In essence, an RNN is a sequence of neural network units where each unit <script type="math/tex">u_t</script> takes input from both <script type="math/tex">u_{t-1}</script> and data vector <script type="math/tex">v_t</script> and produces an output. Today most Recurrent Neural Networks utilize an architecture called <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Long Short Term Memory</a> (LSTM), but for simplicity’s sake the RNN-RBM that we’ll make music with today uses a vanilla RNN.</p>

<p>If you haven’t worked with RNN’s before, Andrej Karpathy’s <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a> is a must read. The RNN <a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">tutorial at wild-ml</a> is great as well.</p>

<h3 id="the-rnn-rbm">The RNN-RBM</h3>

<p>The RNN-RBM was introduced in <a href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription (Boulanger-Lewandowski 2012)</a>. We can think of this powerful model as a series of Restricted Boltzmann Machines whose parameters are determined by an RNN. As we saw in the last post, each RBM in the sequence is capable of modeling a complex and high dimensional probability distribution. Since the RNN conditions each distribution on those of the previous time steps, the network can model the way that the notes change over the course of the song.</p>

<p>Like the RBM, the RNN-RBM is an unsupervised generative model. This means that the objective of the algorithm is to directly model the probability distribution of an unlabeled data set (in this case, music). If you have worked mainly with supervised discriminative algorithms in the past, this may seem like a pretty weird concept. But the RNN-RBM is awesome! After all, you’ve got one model (the RNN) literally learning how to build another model (the RBM). That’s pretty sweet.</p>

<blockquote>
  <p>One caveat: The RNN-RBM that I will describe below is not exactly identical to the one described in <a href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">Boulanger-Lewandowski 2012</a>. I’ve modified the model slightly to produce what I believe to be more pleasant music. All of my changes are superficial however, and the basic architecture of the model remains the same.</p>
</blockquote>

<h3 id="model-architecture">Model Architecture</h3>

<p>The architecture of the RNN-RBM is not tremendously complicated. Each RNN hidden unit is paired with an RBM. RNN hidden unit <script type="math/tex">u_t</script> takes input from data vector <script type="math/tex">v_t</script> (the note or notes at time t) as well as from hidden unit <script type="math/tex">u_{t-1}</script>. The outputs of hidden unit <script type="math/tex">u_t</script> are the parameters of <script type="math/tex">RBM_{t+1}</script>, which takes as input data vector <script type="math/tex">v_{t+1}</script>.</p>

<p>Just like in any model with hidden units, the value of hidden unit <script type="math/tex">u_t</script> encodes something about the current “state” of the sequence. For example, this could be information about the chord that is being played or the current mood of the song.</p>

<p><img src="/img/rnnrbm_color.png" alt="The parameters of each RBM are determined by the output of the RNN" /></p>

<p>In <a href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">Boulanger-Lewandowski 2012</a>, all of the RBMs share the same weight matrix, and only the hidden and visible bias vectors are determined by the outputs of <script type="math/tex">u_t</script>. With this convention, the role of the RBM weight matrix is to specify a consistent prior on all of the RBM distributions (the general structure of music), and the role of the bias vectors is to communicate temporal information (the current state of the song).</p>

<h3 id="model-parameters">Model Parameters</h3>

<blockquote>
  <p>Note: Rather than adopt the naming convention from <a href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">Boulanger-Lewandowski 2012</a>, we use the much more sane naming convention from this <a href="http://deeplearning.net/tutorial/rnnrbm.html">deeplearning tutorial</a>. The image below is also from this tutorial.</p>
</blockquote>

<p>The parameters of the model are the following:</p>

<ul>
  <li><script type="math/tex">W</script>, the weight matrix that is shared by all of the RBMs in the model</li>
  <li><script type="math/tex">W_{uh}</script>, the weight matrix that connects the RNN hidden units to the RBM hidden biases</li>
  <li><script type="math/tex">W_{uv}</script>, the weight matrix that connects the RNN hidden units to the RBM visible biases</li>
  <li><script type="math/tex">W_{vu}</script>, the weight matrix that connects the data vectors to the RNN hidden units</li>
  <li><script type="math/tex">W_{uu}</script>, the weight matrix that connects the the RNN hidden units to each other</li>
  <li><script type="math/tex">b_u</script>, the bias vector for the RNN hidden unit connections</li>
  <li><script type="math/tex">b_v</script>, the bias vector for the RNN hidden unit to RBM visible bias connections. This vector serves as the template for all of the <script type="math/tex">b_v^{t}</script> vectors</li>
  <li><script type="math/tex">b_h</script>, the bias vector for the RNN hidden unit to RBM hidden bias connections. This vector serves as the template for all of the <script type="math/tex">b_h^{t}</script> vectors</li>
</ul>

<p><img src="/img/rnnrbm_figure.png" alt="The parameters of the model" /></p>

<h3 id="training">Training</h3>
<blockquote>
  <p>Note: Before training the RNN-RBM, it is helpful to initialize <script type="math/tex">W</script>, <script type="math/tex">bh</script>, and <script type="math/tex">bv</script> by training an RBM on the dataset, according to the procedure specified in the <a href="http://danshiebler.com/2015-08-10-musical-tensorflow-rbm/">previous post</a>.</p>
</blockquote>

<p>To train the RNN-RBM, we repeat the following procedure:</p>

<ol>
  <li>Use the RNN-to-RBM weight and bias matrices and the state of RNN hidden unit <script type="math/tex">u_{t-1}</script> to determine the bias vectors <script type="math/tex">b_{v}^{t}</script> and <script type="math/tex">b_{h}^{t}</script> for <script type="math/tex">RBM_t</script>.
    <ul>
      <li>
        <script type="math/tex; mode=display">b_{h}^{t} = b_{h} + u_{t-1}W_{uh}</script>
      </li>
      <li>
        <script type="math/tex; mode=display">b_{v}^{t} = b_{v} + u_{t-1}W_{uv}</script>
      </li>
    </ul>
  </li>
  <li>Initialize <script type="math/tex">RBM_t</script> with <script type="math/tex">v_{t}</script> and perform a single iteration of <a href="http://stats.stackexchange.com/questions/10213/can-someone-explain-gibbs-sampling-in-very-simple-words">Gibbs Sampling</a> to sample <script type="math/tex">v_{t}^{*}</script> from <script type="math/tex">RBM_t</script>. See the previous post for a good description of Gibbs sampling.
    <ul>
      <li><script type="math/tex">h_i \backsim \sigma (W^{T}v_t + b_{h}^{t})_i</script>.</li>
      <li><script type="math/tex">v_{t_{i}}^{*} \backsim \sigma (Wh + b_{v}^{t})_i</script>.</li>
    </ul>
  </li>
  <li>Compute the <a href="http://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf">contrastive divergence</a> estimation of the negative log likelihood of <script type="math/tex">v_t</script> with respect to <script type="math/tex">RBM_t</script>. Then, backpropagate this loss through the network to compute the gradients of the network parameters and update the network weights and biases. In practice, TensorFlow will handle the backpropagation and update steps.
    <ul>
      <li>We compute this loss function by taking the difference between the free energies of <script type="math/tex">v_t</script> and <script type="math/tex">v_{t}^{*}</script>.
        <ul>
          <li>
            <script type="math/tex; mode=display">loss = F(v_{t}) - F(v_{t}^{*}) \simeq -log(P(v_t))</script>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Use <script type="math/tex">v_t</script>, the state of RNN hidden unit <script type="math/tex">u_{t-1}</script> and the weight and bias matrices of the RNN to determine the state of RNN hidden unit <script type="math/tex">u_{t}</script>. In the below equation, we can substitute <script type="math/tex">\sigma</script> for other non-linearities, such as <script type="math/tex">tanh</script>.
    <ul>
      <li>
        <script type="math/tex; mode=display">u_{t} = \sigma(b_{u} + v_{t}W_{vu} + u_{t-1}W_{uu})</script>
      </li>
    </ul>
  </li>
</ol>

<h3 id="generation">Generation</h3>

<p>To use the trained network to generate a sequence, we initialize an empty <code class="highlighter-rouge">generated_music</code> array and repeat the same steps as above, with some simple changes. We replace steps 2 and 3 with:</p>

<ul>
  <li>Initialize the visible state of <script type="math/tex">RBM_t</script> with <script type="math/tex">v_{t-1}^{*}</script> (or zeros if <script type="math/tex">t</script> is 0) and perform <script type="math/tex">k</script> steps of Gibbs Sampling to generate <script type="math/tex">v_{t}^{*}</script></li>
  <li>Add <script type="math/tex">v_{t}^{*}</script> to the <code class="highlighter-rouge">generated_music</code> array</li>
</ul>

<p>We also replace the <script type="math/tex">v_{t}</script> in the equation in step 4 with <script type="math/tex">v_{t}^{*}</script>.</p>

<h3 id="data">Data</h3>
<p>The data format is identical to the data format in the <a href="http://danshiebler.com/2015-08-10-musical-tensorflow-rbm/">previous post</a>. In <a href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">Boulanger-Lewandowski 2012</a>, each RBM only generates one timestep, but I’ve found that allowing each RBM to generate 5 or more timesteps actually produces more interesting music. You can see the specifics in the code below.</p>

<h3 id="music">Music</h3>
<p>Before we get to the code, I thought I’d share some examples of the music this network can create. These examples were all produced by training the network on a small dataset of pop music midi files.</p>

<audio src="/audio/14.mp3" controls="" preload=""></audio>
<audio src="/audio/13.mp3" controls="" preload=""></audio>
<audio src="/audio/12.mp3" controls="" preload=""></audio>
<audio src="/audio/11.mp3" controls="" preload=""></audio>
<audio src="/audio/10.mp3" controls="" preload=""></audio>
<audio src="/audio/9.mp3" controls="" preload=""></audio>
<audio src="/audio/8.mp3" controls="" preload=""></audio>
<audio src="/audio/7.mp3" controls="" preload=""></audio>
<audio src="/audio/6.mp3" controls="" preload=""></audio>
<audio src="/audio/5.mp3" controls="" preload=""></audio>
<audio src="/audio/15.mp3" controls="" preload=""></audio>

<h3 id="code">Code</h3>
<p>All of the RNN-RBM code is in <a href="https://github.com/dshieble/Music_RNN_RBM">this directory</a>. If you’re not interested in going through the code and just want to make music, you can follow the instructions in the README.md.</p>

<p>Here is what you need to look at if you are interested in understanding and possibly improving on the code:</p>

<ul>
  <li><a href="https://github.com/dshieble/Music_RNN_RBM/blob/master/weight_initializations.py">weight_initializations.py</a> When you run this file from the command line, it instantiates the parameters of the RNN-RBM and pretrains the RBM parameters by using Contrastive Divergence.</li>
  <li><a href="https://github.com/dshieble/Music_RNN_RBM/blob/master/RBM.py">RBM.py</a> This file contains all of the logic for building and training the RBMs. This is very similar to the RBM code from the previous post, but it has been refactored to fit into the RNN-RBM model. The <code class="highlighter-rouge">get_cd_update</code> function runs an iteration of contrastive divergence to train the RBM during weight initialization, and the <code class="highlighter-rouge">get_free_energy_cost</code> function computes the loss function during training.</li>
  <li><a href="https://github.com/dshieble/Music_RNN_RBM/blob/master/rnn_rbm.py">rnn_rbm.py</a> This file contains the logic to build, train, and generate music with the RNN-RBM. The <code class="highlighter-rouge">rnnrbm</code> function returns the parameters of the model and the <code class="highlighter-rouge">generate</code> function, which we call to generate music.</li>
  <li><a href="https://github.com/dshieble/Music_RNN_RBM/blob/master/rnn_rbm_train.py">rnn_rbm_train.py</a> When you run this file from the command line, it builds an RNN-RBM, sets up logic to compute gradients and update the weights of the model, spins up a TensorFlow session, and runs through the data, training the model.</li>
  <li><a href="https://github.com/dshieble/Music_RNN_RBM/blob/master/rnn_rbm_generate.py">rnn_rbm_generate.py</a> When you run this file from the command line, it builds an RNN-RBM, spins up a TensorFlow session, loads the weights of the RNN-RBM from the <code class="highlighter-rouge">saved_weights_path</code> that you supply, and generates music in the form of midi files.</li>
</ul>

<h3 id="extensions">Extensions</h3>

<p>It’s not too difficult to think of possible extensions to the RNN-RBM architecture. The authors utilize <a href="http://www.icml-2011.org/papers/532_icmlpaper.pdf">Hessian-Free optimization</a> to help train the RNN to better recognize long term dependencies. Another tool that is very useful for representing long term dependencies is <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM</a>. It’s reasonable to suspect that converting the RNN cells to LSTM cells would improve the model’s ability to represent longer term patterns in the sequence.</p>

<p>Another way to increase the modelling power of the network is to replace the RBMs with a more complex model. For example, a <a href="https://www.cs.toronto.edu/~hinton/nipstutorial/nipstut3.pdf">Deep Belief Network</a> is an unsupervised neural network architecture formed from multiple RBMs stacked on top of each other. Unlike RBMs, DBNs can take advantage of their multiple layers to form hierarchical representations of data. In <a href="http://www.academia.edu/16196335/Modeling_Temporal_Dependencies_in_Data_Using_a_DBN-LSTM">this paper</a> the authors build a DBN-LSTM, where the RNN cells are replaced with LSTM cells and the RBMs are replaced with DBNs.</p>

<h3 id="extensions-1">Extensions</h3>

<p>Thanks for joining me today to talk about making music in TensorFlow! If you enjoyed seeing how neural networks can learn how to be creative, you may enjoy some of these other incredible architecures:</p>

<ul>
  <li>
    <p>The <a href="http://arxiv.org/pdf/1508.06576v2.pdf">neural style</a> algorithm is one of the most breathtaking algorithms for computational art ever created. The algorithm repaints a photograph or image in the style of a painting. The algorithm works by training a <a href="http://cs231n.github.io/convolutional-networks/">convolutional neural network</a> to maximize both the generated image’s pixel to pixel coherence with the photograph and the texture similarity of the generated image and the painting.</p>

    <p><img src="/img/neural_images.png" alt="The images from the paper" /></p>

    <p>Here is a <a href="https://github.com/anishathalye/neural-style">TensorFlow implementation</a> and a <a href="https://github.com/jcjohnson/neural-style">torch implementation</a> of the algorithm</p>
  </li>
  <li>
    <p>The <a href="https://arxiv.org/pdf/1502.04623v2.pdf">DRAW</a> neural network is a recurrent neural network architecture for generating images. The network adds a sequencial component to image generation by sliding a virtual “pen” to “draw” an image. You can find an accessible description of the paper <a href="https://github.com/tensorflow/magenta/blob/master/magenta/reviews/draw.md">here</a>.</p>
  </li>
  <li>
    <p>The <a href="https://arxiv.org/pdf/1511.06434v2.pdf">DCGAN</a> architecture is one of the most exciting new neural network architectures. This algorithm involves training 2 “adversarial” neural networks to battle each other. One network generates images, and the other network tries to distinguish the generated images from real images. This architecture has shown incredible success in generating pictures of <a href="https://github.com/Newmu/dcgan_code">bedrooms and faces</a> that look almost real.</p>
  </li>
</ul>


      </article>

      
        <div class="blog-tags">
          Tags:
          
            RNN, RBM, TensorFlow, Python, Music, Neural-Network
          
        </div>
      

      
        <!-- Check if any share-links are active -->




<section id = "social-share-section">

  <!--- Share on Twitter -->
  

  <!--- Share on Facebook -->
  
    <a href="https://www.facebook.com/sharer/sharer.php?u=http://dshieble.github.io/2015-08-17-musical-tensorflow-part-two-the-rnn-rbm/"
      class="btn btn-social-icon btn-facebook" title="Share on Facebook">
      <span class="fa fa-fw fa-facebook" aria-hidden="true"></span>
    </a>
  

  <!--- Share on Google Plus -->
  

  <!--- Share on LinkedIn -->
  
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://dshieble.github.io/2015-08-17-musical-tensorflow-part-two-the-rnn-rbm/"
      class="btn btn-social-icon btn-linkedin" title="Share on LinkedIn">
      <span class="fa fa-fw fa-linkedin" aria-hidden="true"></span>
    </a>
  

</section>


      

      <ul class="pager blog-pager">
        
        <li class="previous">
          <a href="/2015-08-10-musical-tensorflow-part-one-the-rbm/" data-toggle="tooltip" data-placement="top" title="Musical TensorFlow, Part 1 - How to build an RBM in TensorFlow for making music">&larr; Previous Post</a>
        </li>
        
        
      </ul>

      
        <div class="disqus-comments">
          

        </div>
      
    </div>
  </div>
</div>

    <footer>
  <div class="container beautiful-jekyll-footer">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          <li>
            <a href="https://github.com/dshieble" title="GitHub">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
		  
          <li>
            <a href="mailto:danshiebler@gmail.com" title="Email me">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
          <li>
            <a href="https://linkedin.com/in/dan-shiebler-10219b42#Dan Shiebler" title="LinkedIn">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
		  
		  
      
      
		  
        </ul>
        <p class="copyright text-muted">
		  Dan Shiebler
		  &nbsp;&bull;&nbsp;
		  2016

		  
	    </p>
	        <!-- Please don't remove this, keep my open source work credited :) -->
		<p class="theme-by text-muted">
		  Theme by
		  <a href="http://deanattali.com/beautiful-jekyll/">beautiful-jekyll</a>
		</p>
      </div>
    </div>
  </div>
</footer>

  
    






  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script>
      	if (typeof jQuery == 'undefined') {
      	  document.write('<script src="/js/jquery-1.11.2.min.js"></scr' + 'ipt>');
      	}
      </script>
    
  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
	<script src="/js/bootstrap.min.js"></script>
    
  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
	<script src="/js/main.js"></script>
    
  




  
  </body>
</html>
